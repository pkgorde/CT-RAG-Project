{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzIhSh7Lu_sh",
    "outputId": "ad530da0-e516-4f10-fedb-5e0c84c7a318"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "!pip install evaluate\n",
    "!pip install rouge\n",
    "!pip install torch\n",
    "\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import evaluate  # Bleu\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PldaDneExnzV",
    "outputId": "be63d0ed-dc64-42ea-a808-1d487bbf14f1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !ls \"/content/drive/My Drive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WfPsiAisxzZC"
   },
   "outputs": [],
   "source": [
    "# !cd \"/content/drive/My Drive/Colab Notebooks\"\n",
    "model_path = \"Clinical-T5-Large/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iV6lfwo4yOkA",
    "outputId": "5f387b68-1d9c-48ff-a25d-887d00df369b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER = AutoTokenizer.from_pretrained(model_path)\n",
    "MODEL = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "OPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\n",
    "Q_LEN = 512   # Question Length\n",
    "T_LEN = 512    # Target Length\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = \"cuda:0\"\n",
    "MODEL = MODEL.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "4a8a251afaac40589080042033f32143",
      "ba1b621e092d46d38317ef67145a4a7f",
      "fa97894e4c934ccd9d461f578c60a015",
      "db5f5fc974ac48469812bdf911a06de9",
      "2fdb84e3b72b46de9e7e32c85133677d",
      "36cb7e6bd7ae44749d3c7b9af3402a5f",
      "9e3a0c3b94da4796966715806eeee6be",
      "1336d7711863419b9c4118009c3654c0",
      "2dc57028a9be48198df7dde7abf41165",
      "f3fa318426cc4b97b375422fa81b0661",
      "0dbeb8e85f204e2a9ff587d3ad0af2ea",
      "b56852a18ad443c2b833097c9f775db2",
      "38b0c2f2938d43ff80ce067e588fd776",
      "4aef0c61532a4fd99272a202333c4308",
      "22981a1cbd7d4cb1b0f3ca66bb63cfa6",
      "9519ebd8b61a4eda858f4fa53726a16a",
      "dbee5b8a062c400ba515dda4980eabcf",
      "5fdf0941efe341958df86af3a8aa95fb",
      "d397cfb062464ee59501c1a71e514045",
      "ec00a599645d4e13a4727fe402423da5",
      "183d70e1b4f6479aa41e31b6dca85082",
      "cdf42103fe784fa7942f1025a59f1b8b",
      "43369dfa18774c2fb6b637404b70e62a",
      "26f9255180414d3c88fc90eb3d8eac94",
      "09ebd7a0c4a2434c9c4ada66eec8a3a2",
      "3e5fbf44598a4abba21879d1e8dd874a",
      "d51e651546554a0683aba773d7276fad",
      "8a77dc2e0ff7449fa558a6ba3a608eba",
      "393e90b5618a4779a450055a7a5060b3",
      "4b1fc48ef2804652a6f2a84c4b28a0f3",
      "46fc05ca402345248b674b92107661ff",
      "7dc592345fe5424dbb9f8bc3357f44c8",
      "3f794eb48591479e941318f79d9626a3"
     ]
    },
    "id": "wVNLyaJFyqYJ",
    "outputId": "4bc92554-a800-48b7-e978-3845449853df"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dffbf4be6ba4a72bd1b771d5857f2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1d4433f3ea4c889702f39e707aca70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/402M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99da5b9b9a4465fb4fe55f8b39a0948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/158114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"qiaojin/PubMedQA\", \"pqa_unlabeled\")\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"starmpcc/Asclepius-Synthetic-Clinical-Notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKI-ZX0h0Be8",
    "outputId": "fbb15795-679f-4681-9505-8b92297f46ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'note', 'question', 'answer', 'task'],\n",
       "        num_rows: 158114\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SQJuYqJW0ERd",
    "outputId": "e5d14469-e4c7-4342-8f04-cba8bf6fac18"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospital Course Summary:\\n\\nAdmission Date: [I...</td>\n",
       "      <td>What were the key improvements in the patient'...</td>\n",
       "      <td>During the hospital course, the patient's medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discharge Summary:\\n\\nPatient: 52-year-old mal...</td>\n",
       "      <td>How did the patient's treatment for dysphagia ...</td>\n",
       "      <td>During the patient's hospital stay, treatment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discharge Summary:\\n\\nPatient Name: [REDACTED]...</td>\n",
       "      <td>Can you provide a summary of the treatment, ho...</td>\n",
       "      <td>The 45-year-old female patient with a history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DISCHARGE SUMMARY:\\n\\nPatient Name: X\\nMedical...</td>\n",
       "      <td>Based on the given discharge summary, can you ...</td>\n",
       "      <td>The patient with a multifocal invasive mammary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hospital Course:\\n\\nThe patient is a 78-year-o...</td>\n",
       "      <td>What are the key findings and diagnosis of the...</td>\n",
       "      <td>The key findings of the patient include abnorm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Hospital Course Summary:\\n\\nAdmission Date: [I...   \n",
       "1  Discharge Summary:\\n\\nPatient: 52-year-old mal...   \n",
       "2  Discharge Summary:\\n\\nPatient Name: [REDACTED]...   \n",
       "3  DISCHARGE SUMMARY:\\n\\nPatient Name: X\\nMedical...   \n",
       "4  Hospital Course:\\n\\nThe patient is a 78-year-o...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What were the key improvements in the patient'...   \n",
       "1  How did the patient's treatment for dysphagia ...   \n",
       "2  Can you provide a summary of the treatment, ho...   \n",
       "3  Based on the given discharge summary, can you ...   \n",
       "4  What are the key findings and diagnosis of the...   \n",
       "\n",
       "                                              answer  \n",
       "0  During the hospital course, the patient's medi...  \n",
       "1  During the patient's hospital stay, treatment ...  \n",
       "2  The 45-year-old female patient with a history ...  \n",
       "3  The patient with a multifocal invasive mammary...  \n",
       "4  The key findings of the patient include abnorm...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def create_dataframe(context_list, question_list, answer_list):\n",
    "#     if len(context_list) != len(question_list) or len(question_list) != len(answer_list):\n",
    "#         raise ValueError(\"All lists must have the same length.\")\n",
    "\n",
    "#     context_input_list = [' '.join(i['contexts']) for i in context_list]\n",
    "\n",
    "#     data = {\n",
    "#         'context': context_input_list,\n",
    "#         'question': question_list,\n",
    "#         'answer': answer_list\n",
    "#     }\n",
    "\n",
    "#     df = pd.DataFrame(data)\n",
    "#     return df\n",
    "\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Filter the dataset for rows with tasks 'summarization' or 'question answering'\n",
    "filtered_data = df[df['task'].isin(['Summarization', 'Question Answering'])]\n",
    "\n",
    "# Create a new DataFrame with the specified columns\n",
    "filtered_data = filtered_data[['note', 'question', 'answer']]\n",
    "filtered_data.columns = ['context', 'question', 'answer']\n",
    "\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Filtered Clinical Notes DataFrame\", dataframe=filtered_data)\n",
    "\n",
    "filtered_data = filtered_data.reset_index(drop=True)\n",
    "\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "d_jwLQVQ1yZk"
   },
   "outputs": [],
   "source": [
    "# data_df = create_dataframe(dataset['train']['context'], dataset['train']['question'], dataset['train']['long_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ke7A1o0A2jWE",
    "outputId": "ebfdbcb2-9d84-46e7-954d-86a95a6453ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospital Course Summary:\\n\\nAdmission Date: [I...</td>\n",
       "      <td>What were the key improvements in the patient'...</td>\n",
       "      <td>During the hospital course, the patient's medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discharge Summary:\\n\\nPatient: 52-year-old mal...</td>\n",
       "      <td>How did the patient's treatment for dysphagia ...</td>\n",
       "      <td>During the patient's hospital stay, treatment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discharge Summary:\\n\\nPatient Name: [REDACTED]...</td>\n",
       "      <td>Can you provide a summary of the treatment, ho...</td>\n",
       "      <td>The 45-year-old female patient with a history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DISCHARGE SUMMARY:\\n\\nPatient Name: X\\nMedical...</td>\n",
       "      <td>Based on the given discharge summary, can you ...</td>\n",
       "      <td>The patient with a multifocal invasive mammary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hospital Course:\\n\\nThe patient is a 78-year-o...</td>\n",
       "      <td>What are the key findings and diagnosis of the...</td>\n",
       "      <td>The key findings of the patient include abnorm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Hospital Course Summary:\\n\\nAdmission Date: [I...   \n",
       "1  Discharge Summary:\\n\\nPatient: 52-year-old mal...   \n",
       "2  Discharge Summary:\\n\\nPatient Name: [REDACTED]...   \n",
       "3  DISCHARGE SUMMARY:\\n\\nPatient Name: X\\nMedical...   \n",
       "4  Hospital Course:\\n\\nThe patient is a 78-year-o...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What were the key improvements in the patient'...   \n",
       "1  How did the patient's treatment for dysphagia ...   \n",
       "2  Can you provide a summary of the treatment, ho...   \n",
       "3  Based on the given discharge summary, can you ...   \n",
       "4  What are the key findings and diagnosis of the...   \n",
       "\n",
       "                                              answer  \n",
       "0  During the hospital course, the patient's medi...  \n",
       "1  During the patient's hospital stay, treatment ...  \n",
       "2  The 45-year-old female patient with a history ...  \n",
       "3  The patient with a multifocal invasive mammary...  \n",
       "4  The key findings of the patient include abnorm...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_df.head()\n",
    "data_df = filtered_data\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Vv4vJo3W3yAY"
   },
   "outputs": [],
   "source": [
    "class QA_Dataset(Dataset):\n",
    "    def __init__(self, tokenizer, dataframe, q_len, t_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.q_len = q_len\n",
    "        self.t_len = t_len\n",
    "        self.data = dataframe\n",
    "        self.questions = self.data[\"question\"]\n",
    "        self.context = self.data[\"context\"]\n",
    "        self.answer = self.data['answer']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        context = self.context[idx]\n",
    "        answer = self.answer[idx]\n",
    "\n",
    "        question_tokenized = self.tokenizer(question, context, max_length=self.q_len, padding=\"max_length\",\n",
    "                                                    truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "        answer_tokenized = self.tokenizer(answer, max_length=self.t_len, padding=\"max_length\",\n",
    "                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "\n",
    "        labels = torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long)\n",
    "        labels[labels == 0] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n",
    "            \"labels\": labels,\n",
    "            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-Q6kFV1V6J9_"
   },
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "train_data, val_data = train_test_split(filtered_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_sampler = RandomSampler(train_data.index)\n",
    "val_sampler = RandomSampler(val_data.index)\n",
    "\n",
    "qa_dataset = QA_Dataset(TOKENIZER, data_df, Q_LEN, T_LEN)\n",
    "\n",
    "train_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVi3ggl06YeO",
    "outputId": "fb938bb4-ffbf-4f4f-9135-2e1e60c71d06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:   0%|▏                                                            | 19/7959 [00:17<2:00:10,  1.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 23\u001b[0m\n\u001b[1;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m MODEL(\n\u001b[1;32m     16\u001b[0m                   input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m     17\u001b[0m                   attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m     18\u001b[0m                   labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m     19\u001b[0m                   decoder_attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask\n\u001b[1;32m     20\u001b[0m                 )\n\u001b[1;32m     22\u001b[0m OPTIMIZER\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m OPTIMIZER\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     25\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/pk01env/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pk01env/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = 0\n",
    "val_loss = 0\n",
    "train_batch_count = 0\n",
    "val_batch_count = 0\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    MODEL.train()\n",
    "    for batch in tqdm(train_loader, desc=\"Training batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "                          input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          labels=labels,\n",
    "                          decoder_attention_mask=decoder_attention_mask\n",
    "                        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        train_loss += outputs.loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    #Evaluation\n",
    "    MODEL.eval()\n",
    "    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "                          input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          labels=labels,\n",
    "                          decoder_attention_mask=decoder_attention_mask\n",
    "                        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        val_loss += outputs.loss.item()\n",
    "        val_batch_count += 1\n",
    "\n",
    "    print(f\"{epoch+1}/{epochs} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nClo6GZA8Hs"
   },
   "outputs": [],
   "source": [
    "MODEL.save_pretrained(\"Clinical_T5_qa_model_asclepius\")\n",
    "TOKENIZER.save_pretrained(\"Clinical_T5_qa_tokenizer_asclepius\")\n",
    "# /content/drive/My Drive/Colab Notebooks/\n",
    "\n",
    "# Saved files\n",
    "# \"\"\"('qa_tokenizer/tokenizer_config.json',\n",
    "#  'qa_tokenizer/special_tokens_map.json',\n",
    "#  'qa_tokenizer/spiece.model',\n",
    "# 'qa_tokenizer/added_tokens.json',\n",
    "# 'qa_tokenizer/tokenizer.json')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LT0kqa54le-a"
   },
   "outputs": [],
   "source": [
    "# MODEL.save_model(\"/content/drive/My Drive/Colab Notebooks/Clinical_T5_qa_model_actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/43.8 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.8/43.8 kB 533.0 kB/s eta 0:00:00\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\premk\\anaconda3\\envs\\ctdataenv\\lib\\site-packages (from transformers) (24.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB ? eta 0:00:00\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.0->transformers)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\premk\\anaconda3\\envs\\ctdataenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\premk\\anaconda3\\envs\\ctdataenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.1 MB 10.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.7/9.1 MB 9.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.2/9.1 MB 9.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.7/9.1 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.3/9.1 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.9/9.1 MB 10.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.5/9.1 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.2/9.1 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.1/9.1 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.8/9.1 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.7/9.1 MB 13.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.6/9.1 MB 14.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.6/9.1 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 14.2 MB/s eta 0:00:00\n",
      "Using cached huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/15.5 MB 41.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.4/15.5 MB 30.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.8/15.5 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.3/15.5 MB 30.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.0/15.5 MB 32.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.7/15.5 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.5 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.8/15.5 MB 38.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.1/15.5 MB 43.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 38.6 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp312-cp312-win_amd64.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.7/138.7 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 268.5/268.5 kB ? eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp312-none-win_amd64.whl (289 kB)\n",
      "   ---------------------------------------- 0.0/289.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 289.4/289.4 kB 18.6 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.4/2.2 MB 30.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 35.6 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 164.4/164.4 kB ? eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.4/100.4 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "   ---------------------------------------- 0.0/316.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 316.1/316.1 kB 19.1 MB/s eta 0:00:00\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.8/66.8 kB 3.5 MB/s eta 0:00:00\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2024.6.2 charset-normalizer-3.3.2 filelock-3.14.0 fsspec-2024.5.0 huggingface-hub-0.23.2 idna-3.7 numpy-1.26.4 pyyaml-6.0.1 regex-2024.5.15 requests-2.32.3 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.2 urllib3-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xy9zdrICl-On",
    "outputId": "629784c8-cd83-470e-d437-ddd4b6b81781"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\premk\\anaconda3\\envs\\CTDataEnv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'T5ForConditionalGeneration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m      7\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m model2 \u001b[38;5;241m=\u001b[39m \u001b[43mT5ForConditionalGeneration\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Clinical_T5_qa_model_asclepius\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m      9\u001b[0m tokenizer2 \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Clinical_T5_qa_tokenizer_asclepius\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'T5ForConditionalGeneration' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForDocumentQuestionAnswering\n",
    "# model2 = T5ForConditionalGeneration.from_pretrained(\"Clinical_T5_qa_model_asclepius\")\n",
    "# OPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\n",
    "Q_LEN = 512   # Question Length\n",
    "T_LEN = 512    # Target Length\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = \"cuda:0\"\n",
    "model2 = T5ForConditionalGeneration.from_pretrained(\"../Clinical_T5_qa_model_asclepius\").to(DEVICE)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"../Clinical_T5_qa_tokenizer_asclepius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fyGsvjdTm9ax"
   },
   "outputs": [],
   "source": [
    "def predict_answer(context, question, ref_answer=None):\n",
    "    inputs = tokenizer2(question, context, max_length=Q_LEN, padding=\"max_length\", truncation=True, add_special_tokens=True)\n",
    "\n",
    "    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "\n",
    "    outputs = model2.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    predicted_answer = tokenizer2.decode(outputs.flatten(), skip_special_tokens=True)\n",
    "\n",
    "    if ref_answer:\n",
    "        # Load the Bleu metric\n",
    "        bleu = evaluate.load(\"google_bleu\")\n",
    "        score = bleu.compute(predictions=[predicted_answer],\n",
    "                            references=[ref_answer])\n",
    "\n",
    "        print(\"Context: \\n\", context)\n",
    "        print(\"\\n\")\n",
    "        print(\"Question: \\n\", question)\n",
    "        return {\n",
    "            \"Reference Answer: \": ref_answer,\n",
    "            \"Predicted Answer: \": predicted_answer,\n",
    "            \"BLEU Score: \": score\n",
    "        }\n",
    "    else:\n",
    "        return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZYoivP9nQEx",
    "outputId": "877ebab6-3868-4b77-bbec-113ebe8e8d2e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mdata_df\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m question \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m answer \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_df' is not defined"
     ]
    }
   ],
   "source": [
    "context = data_df.iloc[0]['context']\n",
    "question = data_df.iloc[0]['question']\n",
    "answer = data_df.iloc[0]['answer']\n",
    "\n",
    "predict_answer(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShKkKDNLnpA9",
    "outputId": "ab932f76-64ba-449f-e437-258dee1251c9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38731ded496043c08c51120f9bf8546c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c7400f0c3d4475926e4a7259ba84ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: \n",
      "  We may use longitudinal analyses to examine long-term symptom outcomes for patients in the immediate group.\n",
      "Analysis of variance may be used to examine changes in PROMIS scores concerning session attendance and/or the results of the tangibility exercise.\n",
      "A conventional content approach will be used to qualitatively analyze the semi-structured exit interview data.\n",
      "Study Timelines:\n",
      "  Duration of an individual subject’s participation: 16 weeks.\n",
      "  Estimated timeline to enroll all subjects: 1 year.\n",
      "  Estimated timeline to complete the study (complete primary analyses): 1.5 years.\n",
      "Study Endpoints:\n",
      "  Primary Endpoint: Change in PROMIS-29 physical health summary score from before to after intervention in all 48 subjects.\n",
      "  Secondary Endpoints:\n",
      "    Changes in all other PROMIS scores from before to after intervention in all 48 subjects.\n",
      "    Changes in all PROMIS scores between the immediate and wait-list control groups.\n",
      "  Primary or secondary safety endpoints: N/A.\n",
      "Recordings:\n",
      "  This research involves: None of the above (Audio, photographs, video recordings with or without audio).\n",
      "  \n",
      "\n",
      "\n",
      "Question: \n",
      " What are the Study Endpoints?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Reference Answer: ': 'I dont know',\n",
       " 'Predicted Answer: ': 'The Study Endpoints for a patient with PROMIS-29 physical health',\n",
       " 'BLEU Score: ': {'google_bleu': 0.0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"\"\" We may use longitudinal analyses to examine long-term symptom outcomes for patients in the immediate group.\n",
    "Analysis of variance may be used to examine changes in PROMIS scores concerning session attendance and/or the results of the tangibility exercise.\n",
    "A conventional content approach will be used to qualitatively analyze the semi-structured exit interview data.\n",
    "Study Timelines:\n",
    "  Duration of an individual subject’s participation: 16 weeks.\n",
    "  Estimated timeline to enroll all subjects: 1 year.\n",
    "  Estimated timeline to complete the study (complete primary analyses): 1.5 years.\n",
    "Study Endpoints:\n",
    "  Primary Endpoint: Change in PROMIS-29 physical health summary score from before to after intervention in all 48 subjects.\n",
    "  Secondary Endpoints:\n",
    "    Changes in all other PROMIS scores from before to after intervention in all 48 subjects.\n",
    "    Changes in all PROMIS scores between the immediate and wait-list control groups.\n",
    "  Primary or secondary safety endpoints: N/A.\n",
    "Recordings:\n",
    "  This research involves: None of the above (Audio, photographs, video recordings with or without audio).\n",
    "  \"\"\"\n",
    "\n",
    "question = \"What are the Study Endpoints?\"\n",
    "\n",
    "answer = 'I dont know'\n",
    "\n",
    "predict_answer(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJ43arqio7Ih"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09ebd7a0c4a2434c9c4ada66eec8a3a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b1fc48ef2804652a6f2a84c4b28a0f3",
      "max": 158114,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46fc05ca402345248b674b92107661ff",
      "value": 158114
     }
    },
    "0dbeb8e85f204e2a9ff587d3ad0af2ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1336d7711863419b9c4118009c3654c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "183d70e1b4f6479aa41e31b6dca85082": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22981a1cbd7d4cb1b0f3ca66bb63cfa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_183d70e1b4f6479aa41e31b6dca85082",
      "placeholder": "​",
      "style": "IPY_MODEL_cdf42103fe784fa7942f1025a59f1b8b",
      "value": " 402M/402M [00:01&lt;00:00, 255MB/s]"
     }
    },
    "26f9255180414d3c88fc90eb3d8eac94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a77dc2e0ff7449fa558a6ba3a608eba",
      "placeholder": "​",
      "style": "IPY_MODEL_393e90b5618a4779a450055a7a5060b3",
      "value": "Generating train split: 100%"
     }
    },
    "2dc57028a9be48198df7dde7abf41165": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2fdb84e3b72b46de9e7e32c85133677d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36cb7e6bd7ae44749d3c7b9af3402a5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38b0c2f2938d43ff80ce067e588fd776": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbee5b8a062c400ba515dda4980eabcf",
      "placeholder": "​",
      "style": "IPY_MODEL_5fdf0941efe341958df86af3a8aa95fb",
      "value": "Downloading data: 100%"
     }
    },
    "393e90b5618a4779a450055a7a5060b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e5fbf44598a4abba21879d1e8dd874a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7dc592345fe5424dbb9f8bc3357f44c8",
      "placeholder": "​",
      "style": "IPY_MODEL_3f794eb48591479e941318f79d9626a3",
      "value": " 158114/158114 [00:05&lt;00:00, 32723.25 examples/s]"
     }
    },
    "3f794eb48591479e941318f79d9626a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43369dfa18774c2fb6b637404b70e62a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_26f9255180414d3c88fc90eb3d8eac94",
       "IPY_MODEL_09ebd7a0c4a2434c9c4ada66eec8a3a2",
       "IPY_MODEL_3e5fbf44598a4abba21879d1e8dd874a"
      ],
      "layout": "IPY_MODEL_d51e651546554a0683aba773d7276fad"
     }
    },
    "46fc05ca402345248b674b92107661ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a8a251afaac40589080042033f32143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba1b621e092d46d38317ef67145a4a7f",
       "IPY_MODEL_fa97894e4c934ccd9d461f578c60a015",
       "IPY_MODEL_db5f5fc974ac48469812bdf911a06de9"
      ],
      "layout": "IPY_MODEL_2fdb84e3b72b46de9e7e32c85133677d"
     }
    },
    "4aef0c61532a4fd99272a202333c4308": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d397cfb062464ee59501c1a71e514045",
      "max": 401793563,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec00a599645d4e13a4727fe402423da5",
      "value": 401793563
     }
    },
    "4b1fc48ef2804652a6f2a84c4b28a0f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fdf0941efe341958df86af3a8aa95fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7dc592345fe5424dbb9f8bc3357f44c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a77dc2e0ff7449fa558a6ba3a608eba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9519ebd8b61a4eda858f4fa53726a16a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e3a0c3b94da4796966715806eeee6be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b56852a18ad443c2b833097c9f775db2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_38b0c2f2938d43ff80ce067e588fd776",
       "IPY_MODEL_4aef0c61532a4fd99272a202333c4308",
       "IPY_MODEL_22981a1cbd7d4cb1b0f3ca66bb63cfa6"
      ],
      "layout": "IPY_MODEL_9519ebd8b61a4eda858f4fa53726a16a"
     }
    },
    "ba1b621e092d46d38317ef67145a4a7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36cb7e6bd7ae44749d3c7b9af3402a5f",
      "placeholder": "​",
      "style": "IPY_MODEL_9e3a0c3b94da4796966715806eeee6be",
      "value": "Downloading readme: 100%"
     }
    },
    "cdf42103fe784fa7942f1025a59f1b8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d397cfb062464ee59501c1a71e514045": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d51e651546554a0683aba773d7276fad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db5f5fc974ac48469812bdf911a06de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3fa318426cc4b97b375422fa81b0661",
      "placeholder": "​",
      "style": "IPY_MODEL_0dbeb8e85f204e2a9ff587d3ad0af2ea",
      "value": " 2.92k/2.92k [00:00&lt;00:00, 256kB/s]"
     }
    },
    "dbee5b8a062c400ba515dda4980eabcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec00a599645d4e13a4727fe402423da5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f3fa318426cc4b97b375422fa81b0661": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa97894e4c934ccd9d461f578c60a015": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1336d7711863419b9c4118009c3654c0",
      "max": 2921,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2dc57028a9be48198df7dde7abf41165",
      "value": 2921
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
